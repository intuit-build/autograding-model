:imagesdir: etc/images

= Autograding Model

image:https://img.shields.io/badge/JDK-17-yellow.svg[JDK 17]
image:https://github.com/uhafner/autograding-model/workflows/GitHub%20CI/badge.svg[GitHub Actions, link=https://github.com/uhafner/autograding-model/actions/workflows/ci.yml]
image:https://github.com/uhafner/autograding-model/workflows/CodeQL/badge.svg[CodeQL, link=https://github.com/uhafner/autograding-model/actions/workflows/codeql.yml]
image:https://raw.githubusercontent.com/uhafner/autograding-model/main/badges/line-coverage.svg[Line Coverage,link=https://app.codecov.io/gh/uhafner/autograding-model]
image:https://raw.githubusercontent.com/uhafner/autograding-model/main/badges/branch-coverage.svg[Branch Coverage,link=https://app.codecov.io/gh/uhafner/autograding-model]
image:https://raw.githubusercontent.com/uhafner/autograding-model/main/badges/mutation-coverage.svg[Mutation Coverage,link=https://github.com/uhafner/autograding-model/actions/workflows/reporting.yml]
image:https://raw.githubusercontent.com/uhafner/autograding-model/main/badges/warnings.svg[Warnings,link=https://github.com/uhafner/autograding-model/actions/workflows/reporting.yml]

image::summary.png[Scores, width="100%"]

Java library that autogrades projects based on a configurable set of metrics. Currently, you can select from the
following metrics:

- Test statistics (e.g., number of failed tests)
- Code coverage (e.g., line coverage percentage)
- PIT mutation coverage (e.g., missed mutations' percentage)
- Static analysis (e.g., number of warnings)

For each metric you can define the impact on the overall score, and the individual scoring criteria using a JSON
configuration:
[source,json]
----
{
  "analysis": {
    "maxScore": 100,
    "errorImpact": -5,
    "highImpact": -2,
    "normalImpact": -1,
    "lowImpact": -1
  },
  "tests": {
    "maxScore": 100,
    "passedImpact": 0,
    "failureImpact": -5,
    "skippedImpact": -1
  },
  "coverage": {
    "maxScore": 100,
    "coveredPercentageImpact": 0,
    "missedPercentageImpact": -1
  },
  "pit": {
    "maxScore": 100,
    "detectedImpact": 0,
    "undetectedImpact": -1,
    "detectedPercentageImpact": 0,
    "undetectedPercentageImpact": 0
  }
}
----

Creating an aggregated score takes just a few steps:

[source,java]
----
String configuration = "{\"analysis\": { \"maxScore\": 100, \"errorImpact\": -5}}";
AggregatedScore score = new AggregatedScore(configuration);
score.addAnalysisScores(new JenkinsAnalysisSupplier(run));
score.addTestScores(new JenkinsTestSupplier(run));
score.addCoverageScores(new JenkinsCoverageSupplier(run));
score.addPitScores(new JenkinsPitSupplier(run));
----

The actual grading results are then available as properties on the `AggregatedScore` instance.

For each of the 4 supported grading result types you need to implement a supplier implementation that
provides the corresponding details of the project. Please have a look at the
https://github.com/jenkinsci/autograding-plugin[Jenkins plugin] to see an example implementation of these
suppliers.



